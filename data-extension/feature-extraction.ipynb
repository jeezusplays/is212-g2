{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d233c852",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9252540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T15:10:52.668567Z",
     "iopub.status.busy": "2023-09-12T15:10:52.668118Z",
     "iopub.status.idle": "2023-09-12T15:11:06.425269Z",
     "shell.execute_reply": "2023-09-12T15:11:06.424046Z",
     "shell.execute_reply.started": "2023-09-12T15:10:52.668527Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "# import resampy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ebeb0",
   "metadata": {},
   "source": [
    "## Load dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0b9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPath(current_directory,path):\n",
    "    \"\"\"\n",
    "    Converts to absolute path\n",
    "    \"\"\"\n",
    "    combined_path = os.path.join(current_directory,path)\n",
    "    absolute_path = os.path.abspath(combined_path)\n",
    "    return absolute_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1852039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "path_to_dataset_csv = \"csv/dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(path_to_dataset_csv)\n",
    "# Convert to absolute path\n",
    "df['Path'] = df['Path'].apply(lambda x: convertPath(current_directory,x))\n",
    "\n",
    "path = np.array(df.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88dfd1",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40542bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(y=data, rate=rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pitch(data, sample_rate)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb39f52",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810204ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(data, sample_rate):\n",
    "    result = np.array([])\n",
    "\n",
    "    # ZCR\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result = np.hstack((result, zcr))\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft))\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc))\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms))\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel))\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_centroids))\n",
    "\n",
    "    # Spectral Bandwidth\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_bandwidth))\n",
    "\n",
    "    # Spectral Contrast\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_contrast))\n",
    "\n",
    "    # Spectral Rolloff\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_rolloff))\n",
    "\n",
    "    # Chroma Deviation\n",
    "    chroma_std = np.std(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_std))\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # TODO - Consider removing quiet parts of the audio before stitching the audio by 0.5 seconds lengths\n",
    "    # This will require some calculations to get the duration and stepsize right\n",
    "    \n",
    "    hstack = None\n",
    "    step = 5\n",
    "    for i in range(0,30,step):\n",
    "        \n",
    "        if i == 0:\n",
    "            offset=0\n",
    "        else:\n",
    "            i/=10\n",
    "            offset = i-step/10\n",
    "        print(i,offset)\n",
    "\n",
    "        # Split audio according to the stepsize and offset\n",
    "        data, sample_rate = librosa.load(path, offset=offset, duration=step/10)\n",
    "        print(data)\n",
    "    \n",
    "        # without augmentation\n",
    "        res1 = extract_features(data,sample_rate)\n",
    "        result = np.array(res1)\n",
    "        \n",
    "        # data with noise\n",
    "        noise_data = noise(data)\n",
    "        res2 = extract_features(noise_data,sample_rate)\n",
    "        result = np.vstack((result, res2)) # stacking vertically\n",
    "        \n",
    "        # data with stretching and pitching\n",
    "        new_data = stretch(data)\n",
    "        data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "        res3 = extract_features(data_stretch_pitch,sample_rate)\n",
    "        result = np.vstack((result, res3)) # stacking vertically\n",
    "        \n",
    "        if i == 0:\n",
    "            hstack = result\n",
    "        else: hstack = np.hstack((hstack,result))\n",
    "        print(hstack.shape)\n",
    "        \n",
    "    return hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f72264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(df.Path, df.Emotions):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y), df.Path.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a357e",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9d0cf",
   "metadata": {},
   "source": [
    "# Save features to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8d526ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "\n",
    "# Use this naming convension\n",
    "# author_number-of-features_done-PCA?.csv\n",
    "# e.g. sam_10_1.csv > Author: sam, 10 features, has done PCA\n",
    "Features.to_csv('csv/your_filename.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684629d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
